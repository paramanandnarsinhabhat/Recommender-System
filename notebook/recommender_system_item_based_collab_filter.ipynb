{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d5efa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 : Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3ae7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  article_id  rating\n",
      "0        1         456       1\n",
      "1        1        2934       1\n",
      "2        1          82       1\n",
      "3        1        1365       1\n",
      "4        1         221       1\n",
      "Index(['user_id', 'article_id', 'rating'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Step 2 : Reading datsets\n",
    "#Reading train file\n",
    "\n",
    "train_ratings = pd.read_csv('/Users/paramanandbhat/Downloads/Article_Recommendation 2/train.csv')\n",
    "\n",
    "print(train_ratings.head())\n",
    "print(train_ratings.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff1df8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id     website                                              title  \\\n",
      "0        1025  uxmovement  Comment concevoir une procédure pas à pas que ...   \n",
      "1        2328    endeavor  Ressources humaines? Seulement si vous optez p...   \n",
      "2        2469    linkedin           Deux motions de vente différentes. . . .   \n",
      "3        2590  googleblog  Apprentissage large et profond: mieux avec Ten...   \n",
      "4         697       infoq              Agile: manque de compétences en tests   \n",
      "\n",
      "                                             content  \n",
      "0  par anthony le 18/07/16 à 8h02 Si une nouvelle...  \n",
      "1  «Ambassadeurs», «avocats», «porte-parole» d'un...  \n",
      "2  J'ai passé pas mal de temps récemment avec des...  \n",
      "3  \"Apprenez les règles comme un pro, afin de pou...  \n",
      "4  Fran O'Hara, directeur et consultant principal...  \n",
      "Index(['article_id', 'website', 'title', 'content'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Reading article info file\n",
    "\n",
    "article_info = pd.read_csv('/Users/paramanandbhat/Downloads/Article_Recommendation 2/article_info.csv')\n",
    "\n",
    "print(article_info.head())\n",
    "\n",
    "print(article_info.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea862ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  article_id\n",
      "0        1        2607\n",
      "1        1        1445\n",
      "2        1         911\n",
      "3        1         857\n",
      "4        1        2062\n",
      "Index(['user_id', 'article_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Reading test file\n",
    "\n",
    "test_ratings = pd.read_csv('/Users/paramanandbhat/Downloads/Article_Recommendation 2/test.csv')\n",
    "\n",
    "print(test_ratings.head())\n",
    "\n",
    "print(test_ratings.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f6afd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  article_id  rating\n",
      "0        1         456       1\n",
      "1        1        2934       1\n",
      "2        1          82       1\n",
      "3        1        1365       1\n",
      "4        1         221       1    user_id  article_id\n",
      "0        1        2607\n",
      "1        1        1445\n",
      "2        1         911\n",
      "3        1         857\n",
      "4        1        2062    article_id     website                                              title  \\\n",
      "0        1025  uxmovement  Comment concevoir une procédure pas à pas que ...   \n",
      "1        2328    endeavor  Ressources humaines? Seulement si vous optez p...   \n",
      "2        2469    linkedin           Deux motions de vente différentes. . . .   \n",
      "3        2590  googleblog  Apprentissage large et profond: mieux avec Ten...   \n",
      "4         697       infoq              Agile: manque de compétences en tests   \n",
      "\n",
      "                                             content  \n",
      "0  par anthony le 18/07/16 à 8h02 Si une nouvelle...  \n",
      "1  «Ambassadeurs», «avocats», «porte-parole» d'un...  \n",
      "2  J'ai passé pas mal de temps récemment avec des...  \n",
      "3  \"Apprenez les règles comme un pro, afin de pou...  \n",
      "4  Fran O'Hara, directeur et consultant principal...  \n"
     ]
    }
   ],
   "source": [
    "# Displaying the first few rows of each dataset to understand their structure\n",
    "train_ratings.head(), test_ratings.head(), article_info.head()  \n",
    "\n",
    "print(train_ratings.head(), test_ratings.head(), article_info.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076db8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Merge movie (article) information to ratings dataframe\n",
    "train_ratings = train_ratings.merge(article_info[['article_id', 'title']], how='left', on='article_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b94ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Combine article ID and title separated by ': ' and store it in a new column named 'article'\n",
    "train_ratings['article'] = train_ratings['article_id'].map(str) + ': ' + train_ratings['title'].map(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0352b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Keeping only the columns 'article', 'user_id', and 'rating' in the ratings dataframe\n",
    "train_ratings = train_ratings.drop(['article_id', 'title'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc87196f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  rating                                            article\n",
      "0        1       1  456: Obtenez 6 mois d'accès à Pluralsight, la ...\n",
      "1        1       1  2934: La plateforme cloud de Google est désorm...\n",
      "2        1       1    82: La technologie derrière les photos d'aperçu\n",
      "3        1       1  1365: Les VM préemptives de Google Cloud Platf...\n",
      "4        1       1  221: Ray Kurzweil: Le monde ne se détériore pa...\n"
     ]
    }
   ],
   "source": [
    "# Displaying the updated train_ratings dataframe to verify the changes\n",
    "train_ratings.head()\n",
    "\n",
    "print(train_ratings.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b667ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  rating                                            article\n",
      "12270      758       2  1119: Robot trouve un déjeuner de 12 kg à des ...\n",
      "2456       163       1  456: Obtenez 6 mois d'accès à Pluralsight, la ...\n",
      "13393      840       1  204: Aussie utilise des puces Arduino pour rob...\n",
      "14348      913       1  967: L'ancien coach de carrière de Google part...\n",
      "2331       159       2  2653: Un groupe de banques adhère à la technol...        user_id  rating                                            article\n",
      "15564     1003       1  1368: Vous ne reconnaîtrez pas le nouveau mond...\n",
      "14110      901       1               467: Livre: Rétrospectives amusantes\n",
      "6827       460       2  930: Le gouvernement brésilien crée un manuel ...\n",
      "8156       525       2  1631: Cinq compétences de base pour les respon...\n",
      "2214       148       1   2361: La chose la plus difficile en informatique\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Creating train & test data & setting evaluation metric\n",
    "\n",
    "# Splitting the data into training and test datasets\n",
    "X_train, X_test_split = train_test_split(train_ratings, test_size=0.25, random_state=42)\n",
    "\n",
    "# Function to compute the root mean squared error (or RMSE)\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Displaying the first few rows of the train and test splits to verify\n",
    "X_train.head(), X_test_split.head()\n",
    "print(X_train.head(), X_test_split.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "338760df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7: Implementing the simple baseline using the average of all ratings\n",
    "\n",
    "# Define the baseline model to always return the average of all available ratings in the train set\n",
    "def baseline(user_id, movie):\n",
    "    return X_train['rating'].mean()\n",
    "\n",
    "# Function to compute the RMSE score obtained on the test set by a model\n",
    "def rmse_score(model, X_test):\n",
    "    # Construct a list of user-article tuples from the test dataset\n",
    "    id_pairs = zip(X_test['user_id'], X_test['article'])\n",
    "    \n",
    "    # Predict the rating for every user-article tuple\n",
    "    y_pred = np.array([model(user, article) for (user, article) in id_pairs])\n",
    "    \n",
    "    # Extract the actual ratings given by the users in the test data\n",
    "    y_true = np.array(X_test['rating'])\n",
    "    \n",
    "    # Return the final RMSE score\n",
    "    return rmse(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72994b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline rmse is 0.9683927490470934\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the RMSE for the baseline model\n",
    "baseline_rmse = rmse_score(baseline, X_test_split)\n",
    "print(\"Baseline rmse is\" ,baseline_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1c398ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8: Item-Based Collaborative Filtering with Simple Item Mean\n",
    "\n",
    "# STEP 8.1: Build the ratings matrix using pivot_table function\n",
    "r_matrix = X_train.pivot_table(values='rating', index='user_id', columns='article')\n",
    "\n",
    "# STEP 8.2: Item-Based Collaborative Filter using Mean Ratings\n",
    "def cf_item_mean(user_id, movie):\n",
    "    # Compute the mean of all the ratings given by the user\n",
    "    mean_rating = r_matrix.loc[user_id].mean()\n",
    "\n",
    "    return mean_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8030066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for the Mean model 0.9151755464151978\n"
     ]
    }
   ],
   "source": [
    "# Compute RMSE for the Mean model\n",
    "rmse_item_mean = rmse_score(cf_item_mean, X_test_split)\n",
    "rmse_item_mean\n",
    "print('RMSE for the Mean model' ,rmse_item_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83d77105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for weighted mean model 1.0315843646823222\n",
      "RMSe using Grid search 1.1156214167716878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/paramanandbhat/Downloads/item based/item_based_predicted_ratings.csv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# STEP 9: Item-Based Collaborative Filtering with Similarity Weighted Mean\n",
    "\n",
    "# Creating a dummy ratings matrix with all null values imputed to 0\n",
    "r_matrix_dummy = r_matrix.copy().fillna(0)\n",
    "\n",
    "# Compute the cosine similarity matrix using the dummy ratings matrix\n",
    "cosine_sim = cosine_similarity(r_matrix_dummy.T, r_matrix_dummy.T)\n",
    "\n",
    "# Convert into pandas dataframe \n",
    "cosine_sim = pd.DataFrame(cosine_sim, index=r_matrix.columns, columns=r_matrix.columns)\n",
    "\n",
    "# Item-Based Collaborative Filter using Weighted Mean Ratings\n",
    "def cf_item_wmean(user_id, movie_id):\n",
    "    if movie_id in r_matrix:\n",
    "        # Get the similarity scores for the item in question with every other item\n",
    "        sim_scores = cosine_sim[movie_id]\n",
    "\n",
    "        # Get the movie ratings for the user in question\n",
    "        m_ratings = r_matrix.loc[user_id]\n",
    "\n",
    "        # Extract the indices containing NaN in the m_ratings series\n",
    "        idx = m_ratings[m_ratings.isnull()].index\n",
    "\n",
    "        # Drop the NaN values from the m_ratings Series and corresponding scores\n",
    "        m_ratings = m_ratings.dropna()\n",
    "        sim_scores = sim_scores.drop(idx)\n",
    "\n",
    "        # Compute the final weighted mean, if denominator is not zero\n",
    "        if sim_scores.sum() != 0:\n",
    "            wmean_rating = np.dot(sim_scores, m_ratings) / sim_scores.sum()\n",
    "        else:\n",
    "            # Default to user's mean if there are no similar items\n",
    "            wmean_rating = r_matrix.loc[user_id].mean()\n",
    "    else:\n",
    "        # Default to train set mean rating in the absence of any information\n",
    "        wmean_rating = X_train['rating'].mean()\n",
    "\n",
    "    return wmean_rating\n",
    "\n",
    "# Compute RMSE for the Weighted Mean model\n",
    "rmse_item_wmean = rmse_score(cf_item_wmean, X_test_split)\n",
    "rmse_item_wmean\n",
    "\n",
    "print(\"RMSE for weighted mean model\",rmse_item_wmean)\n",
    "\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.prediction_algorithms import KNNWithMeans\n",
    "\n",
    "# STEP 10: Grid Search for Neighbourhood Size and Similarity Measure\n",
    "\n",
    "# Reader object to import ratings from X_train\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Storing Data in surprise format from X_train\n",
    "data = Dataset.load_from_df(X_train[['user_id', 'article', 'rating']], reader)\n",
    "\n",
    "# Defining the parameter grid\n",
    "param_grid = {\n",
    "    'k': [5, 10, 20],  # Number of nearest neighbors to consider\n",
    "    'sim_options': {\n",
    "        'name': ['msd', 'cosine', 'pearson'],  # Different similarity metrics\n",
    "        'user_based': [False]  # Item-based CF\n",
    "    }\n",
    "}\n",
    "\n",
    "# GridSearchCV for parameter tuning\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=5, n_jobs=-1)\n",
    "\n",
    "# Fitting the grid search to the data\n",
    "gs.fit(data)\n",
    "\n",
    "# Best RMSE score and the corresponding parameters\n",
    "best_rmse = gs.best_score['rmse']\n",
    "best_params = gs.best_params['rmse']\n",
    "\n",
    "best_rmse, best_params\n",
    "\n",
    "print(\"RMSe using Grid search\", best_rmse)\n",
    "\n",
    "# Prepare the Test Dataset by merging with the article info\n",
    "test_ratings_merged = test_ratings.merge(article_info[['article_id', 'title']], how='left', on='article_id')\n",
    "test_ratings_merged['article'] = test_ratings_merged['article_id'].map(str) + ': ' + test_ratings_merged['title'].map(str)\n",
    "\n",
    "# Function to predict ratings using the Weighted Mean model\n",
    "def predict_ratings(test_set, rating_model):\n",
    "    predictions = []\n",
    "    for index, row in test_set.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        article_id = row['article']\n",
    "        predicted_rating = rating_model(user_id, article_id)\n",
    "        predictions.append(predicted_rating)\n",
    "    return predictions\n",
    "\n",
    "# Predicting the ratings for the test set\n",
    "test_ratings_merged['rating'] = predict_ratings(test_ratings_merged, cf_item_wmean)\n",
    "\n",
    "# Preparing the final output with required columns\n",
    "final_output = test_ratings_merged[['user_id', 'article_id', 'rating']]\n",
    "\n",
    "# Displaying the first few rows of the final output\n",
    "final_output.head()\n",
    "\n",
    "# Saving the final output to a CSV file\n",
    "output_file_path = '/Users/paramanandbhat/Downloads/item based/item_based_predicted_ratings.csv'\n",
    "final_output.to_csv(output_file_path, index=False)\n",
    "\n",
    "output_file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4feb43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
